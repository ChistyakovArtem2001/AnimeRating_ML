{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANl-B73T28Q3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from xgboost import XGBRegressor\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "class AnimeDataProcessor:\n",
        "    def __init__(self, file_path):\n",
        "        self.df = pd.read_csv(file_path)\n",
        "        self.tags_df = pd.DataFrame()\n",
        "        self.warning_df = pd.DataFrame()\n",
        "        self._clean_data()\n",
        "        self._feature_engineering()\n",
        "\n",
        "    def _clean_data(self):\n",
        "        self.df.Type = self.df.Type.apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
        "\n",
        "    def _feature_engineering(self):\n",
        "        def isNaN(num):\n",
        "            return num != num\n",
        "\n",
        "        self.df['warnings_count'] = self.df.Content_Warning.apply(lambda x: len(x.split(',,')) if not isNaN(x) else 0)\n",
        "        self.df['rel_anim_count'] = self.df.Related_anime.apply(lambda x: len(x.split(',')) if not isNaN(x) else 0)\n",
        "        self.df['rel_mang_count'] = self.df.Related_Mange.apply(lambda x: len(x.split(',')) if not isNaN(x) else 0)\n",
        "        self.df['voice_act_count'] = self.df.Voice_actors.apply(lambda x: len(x.split(',')) if not isNaN(x) else 0)\n",
        "        self.df['staff_count'] = self.df.staff.apply(lambda x: len(x.split(',')) if not isNaN(x) else 0)\n",
        "        self.df['tags_count'] = self.df.Tags.apply(lambda x: len(x.split(',')) if not isNaN(x) else 0)\n",
        "        self.df['rel_media_count'] = self.df.rel_anim_count + self.df.rel_mang_count\n",
        "\n",
        "        self.df.Content_Warning = self.df.Content_Warning.apply(lambda x: x.split(',,') if not isNaN(x) else np.nan)\n",
        "        self.df.Tags = self.df.Tags.apply(lambda x: x.split(',') if not isNaN(x) else np.nan)\n",
        "\n",
        "        self.df.drop(['Related_Mange', 'Related_anime', 'Voice_actors', 'staff', 'End_year'], axis=1, inplace=True)\n",
        "\n",
        "    def visualize_data(self):\n",
        "        cols_for_bar = ['Release_season', 'Type']\n",
        "\n",
        "        for col in cols_for_bar:\n",
        "            plt.figure(figsize=(15, 15))\n",
        "            sns.barplot(y=self.df[col], x=self.df[col].index, ci=None)\n",
        "            plt.title('Распределение {}'.format(col), size=20)\n",
        "            plt.show()\n",
        "\n",
        "        plt.figure(figsize=(15, 7))\n",
        "        sns.displot(self.df.Release_year, height=7)\n",
        "        plt.title('Распределение года выпуска', size=18)\n",
        "        plt.show()\n",
        "\n",
        "        plt.figure(figsize=(15, 7))\n",
        "        sns.displot(self.df.Rating, height=7, kde=True)\n",
        "        plt.title(\"Распределение рейтинга\", size=18)\n",
        "        plt.show()\n",
        "\n",
        "        top_studios = self.df.Studio.value_counts()[:15]\n",
        "        plt.figure(figsize=(15, 7))\n",
        "        sns.barplot(y=top_studios.index, x=top_studios, ci=False)\n",
        "        plt.title('Количество произведенных студиями аниме', size=20)\n",
        "        plt.show()\n",
        "\n",
        "        studios_more_20 = list(self.df.Studio.value_counts().index[:111])\n",
        "        top_studios_rtg = self.df[self.df.Studio.isin(studios_more_20)].groupby('Studio').Rating.mean().sort_values(\n",
        "            ascending=False)[:15]\n",
        "        plt.figure(figsize=(15, 7))\n",
        "        sns.barplot(y=top_studios_rtg.index, x=top_studios_rtg.values).set_title('Лучшие студии по рейтингу с более чем 20 аниме', size=20)\n",
        "        plt.show()\n",
        "\n",
        "        plt.figure(figsize=(15, 7))\n",
        "        sns.boxplot(x=self.df.Type, y=self.df.Rating, palette='mako')\n",
        "        plt.title('Влияние типа аниме на рейтинг', size=20)\n",
        "        plt.show()\n",
        "\n",
        "        plt.figure(figsize=(15, 7))\n",
        "        data_for_box = self.df[self.df.Type.isin(['TV', 'Web'])]\n",
        "        sns.boxplot(x='Type', y='Rating', hue='Release_season', data=data_for_box, palette='mako')\n",
        "        plt.title(\"Влияние сезона выпуска на рейтинг TV-шоу и веб-сериалов\", size=20)\n",
        "        plt.show()\n",
        "\n",
        "        plt.figure(figsize=(15, 15))\n",
        "        num_cols = ['Rating', 'Episodes', 'Release_year', 'warnings_count', 'rel_anim_count', 'rel_mang_count',\n",
        "                    'voice_act_count', 'staff_count', 'tags_count', 'rel_media_count']\n",
        "        sns.heatmap(data=self.df[num_cols].corr(), annot=True, fmt='0.3f', cmap='crest')\n",
        "\n",
        "        df_piv = pd.DataFrame({'Rating': self.df[num_cols].corr().iloc[0]},\n",
        "                              index=self.df[num_cols].corr().iloc[0].index)\n",
        "        rating_corr = self.df[num_cols].corr().iloc[0]\n",
        "        plt.figure(figsize=(15, 1))\n",
        "        df_piv = pd.DataFrame({cname: rating_corr[rating_corr.index == cname].iloc[0] for cname in rating_corr.index},\n",
        "                              index=['Rating'])\n",
        "\n",
        "        sns.heatmap(df_piv, annot=True, fmt='0.3f', cmap='crest')\n",
        "        plt.xticks(rotation=35)\n",
        "\n",
        "        all_text = ''.join([desc for desc in list(self.df.Description) if isinstance(desc, str)])\n",
        "        wordcloud = WordCloud(\n",
        "            background_color='white',\n",
        "            collocations=False,\n",
        "            colormap='winter_r'\n",
        "        )\n",
        "        wordcloud.generate(all_text)\n",
        "\n",
        "        plt.figure(figsize=(15, 7))\n",
        "        plt.imshow(wordcloud, interpolation='bilinear')\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "        web_text = ''.join([desc for desc in list(self.df[self.df.Type == 'Web'].Description) if isinstance(desc, str)])\n",
        "        TV_text = ''.join([desc for desc in list(self.df[self.df.Type == 'TV'].Description) if isinstance(desc, str)])\n",
        "\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "        for ax, text, name in zip(axes, [web_text, TV_text], ['Web', 'TV']):\n",
        "            wc = WordCloud(background_color='white').generate(text)\n",
        "            ax.imshow(wc)\n",
        "            ax.axis('off')\n",
        "            ax.set_title(name, size=30)\n",
        "\n",
        "        self.df.drop('Description', axis=1, inplace=True)\n",
        "\n",
        "    def process_data(self):\n",
        "        all_tags = []\n",
        "\n",
        "        for i in range(len(self.df)):\n",
        "            if not self.isNaN(self.df.loc[i, 'Tags']):\n",
        "                all_tags += self.df.loc[i, 'Tags']\n",
        "\n",
        "        print('Количество уникальных тегов: {}'.format(len(set(all_tags))))\n",
        "\n",
        "        from collections import Counter\n",
        "\n",
        "        tags_df = pd.DataFrame()\n",
        "\n",
        "        first_n_tags = 200\n",
        "        viable_tags = [tag for tag, value in Counter(all_tags).most_common(first_n_tags)]\n",
        "\n",
        "        for i in range(len(self.df)):\n",
        "            tags = self.df.loc[i, 'Tags']\n",
        "\n",
        "            if not self.isNaN(tags):\n",
        "                tags_dict = {tag: 1 for tag in tags if tag in viable_tags}\n",
        "                tags_df = pd.concat([tags_df, pd.Series(tags_dict, name=i)], axis=1)\n",
        "\n",
        "        tags_df = tags_df.T.fillna(0)\n",
        "\n",
        "        warning_df = pd.DataFrame()\n",
        "\n",
        "        all_warnings = []\n",
        "        for i in range(len(self.df)):\n",
        "            if not self.isNaN(self.df.loc[i, 'Content_Warning']):\n",
        "                all_warnings += self.df.loc[i, 'Content_Warning']\n",
        "        warnings = list(set(all_warnings))\n",
        "\n",
        "        for i in range(len(self.df)):\n",
        "            warns = self.df.loc[i, 'Content_Warning']\n",
        "\n",
        "            if not self.isNaN(warns):\n",
        "                warning_dict = {'cw_' + warning: 1 for warning in warns if warning in warnings}\n",
        "                warning_df = pd.concat([warning_df, pd.Series(warning_dict, name=i)], axis=1)\n",
        "\n",
        "        warning_df = warning_df.T.fillna(0)\n",
        "\n",
        "        self.df = pd.concat([self.df, tags_df, warning_df], axis=1)\n",
        "        self.df.dropna(subset=['Rating'], inplace=True)\n",
        "\n",
        "    def train_model(self):\n",
        "        features = ['Type', 'Episodes', 'Release_year', 'Release_season', 'Studio', 'warnings_count', 'rel_anim_count',\n",
        "                    'rel_mang_count', 'voice_act_count',\n",
        "                    'rel_media_count', 'staff_count', 'tags_count'] + list(self.tags_df.columns) + list(self.warning_df.columns)\n",
        "        X = self.df[features]\n",
        "        y = self.df.Rating\n",
        "\n",
        "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)\n",
        "        categorical_cols = ['Type', 'Release_season', 'Studio']\n",
        "        numerical_cols = ['Episodes', 'Release_year', 'warnings_count', 'rel_media_count', 'staff_count',\n",
        "                          'tags_count', 'rel_anim_count',\n",
        "                          'rel_mang_count', 'voice_act_count'] + list(self.tags_df.columns) + list(self.warning_df.columns)\n",
        "\n",
        "        numerical_transformer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "        categorical_transformer = Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "        ])\n",
        "\n",
        "        preprocessor = ColumnTransformer(transformers=[\n",
        "            ('num', numerical_transformer, numerical_cols),\n",
        "            ('cat', categorical_transformer, categorical_cols)\n",
        "        ])\n",
        "\n",
        "        model = XGBRegressor(\n",
        "            learning_rate=0.05,\n",
        "            n_estimators=300,\n",
        "            max_depth=6,\n",
        "            min_child_weight=1,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8,\n",
        "            objective='reg:squarederror',\n",
        "            n_jobs=-1,\n",
        "            random_state=1\n",
        "        )\n",
        "\n",
        "        my_pipeline = Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('model', model)\n",
        "        ])\n",
        "\n",
        "        my_pipeline.fit(X_train, y_train)\n",
        "        preds = my_pipeline.predict(X_valid)\n",
        "        mae = mean_absolute_error(y_valid, preds)\n",
        "        print('Средняя абсолютная ошибка: {}'.format(mae))\n",
        "\n",
        "        for i in range(20):\n",
        "            print('Предсказано: {:.2f};\\n     Реальное: {};\\n'.format(preds[i], y_valid.iloc[i]))\n",
        "\n",
        "        plt.figure(figsize=(10, 7))\n",
        "        plt.scatter(y_valid, preds)\n",
        "        plt.plot([y_valid.min(), y_valid.max()], [y_valid.min(), y_valid.max()], \"k--\", color=\"red\")\n",
        "        plt.xlabel('Фактические', weight=\"bold\")\n",
        "        plt.ylabel('Прогнозируемые', weight=\"bold\")\n",
        "        plt.grid(color='black', linestyle='--', linewidth=0.2)\n",
        "        plt.title('Фактические значения vs прогнозируемые значения')\n",
        "        plt.show()\n",
        "\n",
        "        mse_rf = mean_squared_error(y_valid, preds)\n",
        "        print(\"RMSE: {:.4f} $ \".format(np.sqrt(mse_rf)))\n",
        "        print(\"R2: {:.2f} %\".format(r2_score(y_valid, preds) * 100))\n",
        "\n",
        "    def isNaN(self, num):\n",
        "        return num != num\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vTYZ6SWtz_1sqMZm-ClUdWHgRON7x1atN5DXdFj1xFuBKdSzls7ZzgRxWL554ohQD4fXGjQg_cCrL-T/pub?output=csv\""
      ],
      "metadata": {
        "id": "zgs9rsiG3VAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anime_processor = AnimeDataProcessor(url)"
      ],
      "metadata": {
        "id": "SAmykwNz3ez2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anime_processor.visualize_data()"
      ],
      "metadata": {
        "id": "YsA_Fdf5DWqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anime_processor.process_data()\n",
        "anime_processor.train_model()"
      ],
      "metadata": {
        "id": "Uy0-S86LDTJn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}